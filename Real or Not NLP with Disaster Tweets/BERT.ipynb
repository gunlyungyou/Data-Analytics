{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('C:/Users/ASUS/Documents/kaggle data/Real or Not NLP with Disaster Tweets/nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert model +  logistic for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = BertModel.from_pretrained('bert-base-uncase')\n",
    "        self.fc1 = torch.nn.Linear(768,1)\n",
    "        \n",
    "    def forward(self, ids, masks):\n",
    "        x = self.base_model(ids, attention_mask = masks)[1]\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = 'C:/Users/ASUS/Documents/kaggle data/Real or Not NLP with Disaster Tweets/nlp-getting-started/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(path_to_model, 'model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device ='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(text, max_len=512):\n",
    "    \n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = text[:max_len-2]\n",
    "    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "    tokens += [0] * (max_len - len(input_sequence))\n",
    "    pad_masks = [1] * len(input_sequence) + [0] * (max_len - len(input_sequence))\n",
    "    \n",
    "    return tokens, pad_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, test_tokens, test_pad_masks):\n",
    "        \n",
    "        super(TestDataset, self).__init__()\n",
    "        self.test_tokens = test_tokens\n",
    "        self.test_pad_masks = test_pad_masks\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tokens = self.test_tokens[index]\n",
    "        masks = self.test_pad_masks[index]\n",
    "        \n",
    "        return (tokens, masks)\n",
    "    \n",
    "    def __len__(self,):\n",
    "        \n",
    "        return len(self.test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = []\n",
    "test_pad_masks = []\n",
    "for text in test_df.text:\n",
    "    tokens, masks = bert_encode(text)\n",
    "    test_tokens.append(tokens)\n",
    "    test_pad_masks.append(masks)\n",
    "    \n",
    "test_tokens = np.array(test_tokens)\n",
    "test_pad_masks = np.array(test_pad_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\n",
    "    test_tokens=test_tokens,\n",
    "    test_pad_masks=test_pad_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_preds = []\n",
    "for (tokens, masks) in test_dataloader:\n",
    "\n",
    "    y_pred = model(\n",
    "                torch.tensor(tokens, dtype=torch.long).to(device),\n",
    "                torch.tensor(masks, dtype=torch.long).to(device),\n",
    "            )\n",
    "    y_preds += y_pred.detach().cpu().numpy().squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
